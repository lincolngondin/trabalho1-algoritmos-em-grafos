Many real-world problems can be transformed into optimization problems, which can be classified into convex and non-convex. Although convex problems are almost completely studied in theory, many related algorithms to many non-convex problems do not work well and we need more optimization techniques. As a swarm intelligence optimization algorithm, the Fireworks Algorithm(FWA) has been widely studied and applied to many real-world scenarios, even including large language model fine-tuning. But the current fireworks algorithm still has a number of problems. Firstly, as a heuristic algorithm, its performance on convex problems cannot match the SOTA results, and can even be said to be unsatisfactory; secondly, the sampling methods (explosion) of most FWA variants are still uniform sampling, which is actually inefficient in high dimensional cases. This work of ours proposes a new student's t-distribution based FWA(TFWA) with a solid theoretical foundation, which fully utilizes the advantage that student's t-distribution can adjust the parameters (degrees of freedom) and thus adjust the exploitation capability. We have fully experimented on mainstream benchmarks CEC2013 and CEC2017, which proves that TFWA not only becomes the strongest variant of the fireworks algorithm, but also achieves results comparable to SOTA on the test set, and its performance is far superior to that of the SOTA algorithm in some scenarios with a large number of extreme points.